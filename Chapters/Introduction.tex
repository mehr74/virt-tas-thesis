%!TEX root = ../Thesis.tex

%---------------------------------------------------------------------------------------------%
% a paragraph about virtualization, that is widely used
Virtualization has gain a lot of popularity during the last two decades. Enabling fast 
provisioning, increasing the availability time, and reducing the maintenance costs
for users are a few reasons of the gained popularity. Moreover, by multiplexing 
multiple virtual machines (VMs) on a same physical server less enegry gets consumed, 
which makes virtualization enviromental friendly and even more popular thesedays.

%---------------------------------------------------------------------------------------------%
% a paragraph about networking in virtualized environment
Public cloud providers such as Amazon Web Services (AWS), Microsoft Azure, and Google Cloud
Platform (GCP) are expanding the range of workloads which can be spilled over virtualized environments. 
These  vendors, in addition to providing high number of VMs with increased performance, have made 
it possible for public tenants to migrate their home workloads without changing the 
on-premises networking configurations. Furthermore, the users of these environments
benefit from supplied address spaces, security groups and ACLs, scalable load balancers, 
bandwidth metering, QoS, and more \cite{firestone2017vfp}.


%---------------------------------------------------------------------------------------------%
% about new stacks for processing tcp
The workloads applied by cloud tenants are bursty, which require high throughput and low latecy 
network access. It was this requirement, which motivated cloud providers to increase their networking 
speeds by more than 40x and more in a span of only a few years \cite{firestone2018azure}. While 
networking speed is growing fast, the CPU improvement has become slower, and has experienced the 
end of Moore's law \cite{esmaeilzadeh2011dark}. Hence efficient packet processing is becoming 
more and more important. 

Due to poor cache allocation, costly context switches, and resources sharing across different 
cores, Linux TCP packet processing is considered as inefficient for modern data center 
networking \cite{kaufmann2019tas, shashidhara2022flextoe}. Different techniques tried 
to address the issue by reducing the overheads and improving the conventional TCP stack.
These techniques include bypassing kernel to enable direct NIC access from user-space
\cite{belay2014ix, jeong2014mtcp, prekas2017zygos}
using receive side scaling (RSS) to carefuly steering and processing packets on multi-cores 
architecture \cite{marty2019snap, kaufmann2019tas}, and offloading packet processing to 
NICs with computation capabilities 
\cite{arashloo2020enabling, lin2020panic, firestone2018azure, shashidhara2022flextoe}. 


%---------------------------------------------------------------------------------------------%
% define problem 
% why modern tcp stacks are not applicable by VMs
Although these techniques have imporved the performance of end-host packet processing, they 
suffer from two fundamental implications when it comes to providing high throughput and 
low latency network access for applications residing on VMs.


% operators hesitate to deploy new stacks 
\textbf{Implication I.} Majority of these techniques are proposed only for applications running
on bare metal servers, and they do not provide the rich virtualization features required in 
multi-tentant datacenters. Hence, cloud providers hesitate to deploy the techniques for
their tenants and applications still use the conventional TCP packet processing.

% users hesitate to use new stacks 
\textbf{Implication II.} Cloud tenants are only concerned with performance of their applications,
and they do not want the maintenance of the network stack to fallout on their shoulders. Deploying 
new packet processing stacks requires extensive testing and comes with the risk of 
misconfigurations. Therefore, cloud tenants hesitate to deploy the techniques in trade with
high throughput and low latency.

%---------------------------------------------------------------------------------------------%
% goal
% we asked ourself whether it is possible to provide
% TODO extend 
\textbf{Goal} In this thesis, we ask the following question: \emph{How can we provide virtualization 
features on top of the modern stacks?} In response, we enrich Virt-TAS with virtualization features.
Virt-TAS is a TCP acceleration service for virtualized environments targeted at applications 
that require low latency and high throughput. It runs as a service alongside the host and provides 
a fast-path for common send and receive operations, through which it reduces the virtualization 
overheads incurred by the hypervisor and guest operating system \cite{florian2021virttas}. 

%---------------------------------------------------------------------------------------------%
% briefly explain how VirtTAS works
% TODO extend
To avoid reinventing the wheel, instead of implementing a virtual switch from scratch, we
complement Virt-TAS by integrating Open vSwitch (OVS) \cite{pfaff2015design}. OVS is a virtual
 switch which is adopted inmany data center networks. It is also a component of VMware's NSX 
 product, used by thousands of customers \cite{tu2021revisiting}.

%---------------------------------------------------------------------------------------------%
% what are the main contributions of this thesis
% TODO extend
We have the following contribution.
\begin{itemize}
    \item Extend TAS to support groups
    \item Use OVS to steer packets from TAS
    \item provide implementation which integrates TAS to OVS.
    \item evaluation.
\end{itemize}

%---------------------------------------------------------------------------------------------%
% structure of next sections
% TODO extend
The rest of this thesis is organized in this order.




